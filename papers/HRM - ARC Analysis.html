<!DOCTYPE html><html><head>
      <title>The Hidden Drivers of HRM's Performance on ARC-AGI</title>
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/katex.min.css">
      
      
      
      
      
      <style>
      pre{font-family:Menlo,Monaco,Consolas,'Courier New',monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;padding:1em;margin:.5em 0;overflow:auto;line-height:1.5;tab-size:4;hyphens:none;color:#c5c8c6;background-color:#27292c!important;border:#43484c;border-radius:3px}pre[class*=language-]{padding:1em}code[class*=language-] .token.cdata,code[class*=language-] .token.comment,code[class*=language-] .token.doctype,code[class*=language-] .token.prolog,pre[class*=language-] .token.cdata,pre[class*=language-] .token.comment,pre[class*=language-] .token.doctype,pre[class*=language-] .token.prolog{color:#7c7c7c}code[class*=language-] .token.punctuation,pre[class*=language-] .token.punctuation{color:#96cbfe}code[class*=language-] .namespace,pre[class*=language-] .namespace{opacity:.7}code[class*=language-] .token.constant,pre[class*=language-] .token.constant{color:#9c9}code[class*=language-] .token.boolean,code[class*=language-] .token.function-name,code[class*=language-] .token.number,pre[class*=language-] .token.boolean,pre[class*=language-] .token.function-name,pre[class*=language-] .token.number{color:#ff73fd}code[class*=language-] .token.tag,pre[class*=language-] .token.tag{color:#96cbfe}code[class*=language-] .token.selector,pre[class*=language-] .token.selector{color:#96cbfe}code[class*=language-] .token.attr-name,pre[class*=language-] .token.attr-name{color:#c6c5fe}code[class*=language-] .token.string,pre[class*=language-] .token.string{color:#a8ff60}code[class*=language-] .token.char,pre[class*=language-] .token.char{color:#ff8000}code[class*=language-] .token.entity,pre[class*=language-] .token.entity{color:#ffd2a7}code[class*=language-] .token.url,pre[class*=language-] .token.url{color:#7c7c7c}code[class*=language-] .token.operator,pre[class*=language-] .token.operator{color:#ededed}code[class*=language-] .token.atrule,code[class*=language-] .token.attr-value,code[class*=language-] .token.keyword,pre[class*=language-] .token.atrule,pre[class*=language-] .token.attr-value,pre[class*=language-] .token.keyword{color:#cfcb90}code[class*=language-] .token.function,pre[class*=language-] .token.function{color:#ffd2a7}code[class*=language-] .token.class-name,pre[class*=language-] .token.class-name{color:#ffd2a7}code[class*=language-] .token.variable,pre[class*=language-] .token.variable{color:#c6c5fe}code[class*=language-] .token.important,code[class*=language-] .token.regex,pre[class*=language-] .token.important,pre[class*=language-] .token.regex{color:#e9c062}code[class*=language-] .token.bold,code[class*=language-] .token.important,pre[class*=language-] .token.bold,pre[class*=language-] .token.important{font-weight:700}code[class*=language-] .token.italic,pre[class*=language-] .token.italic{font-style:italic}code[class*=language-] .token.entity,pre[class*=language-] .token.entity{cursor:help}pre[data-line]{position:relative;padding:1em 0 1em 3em}pre[data-line] .line-highlight-wrapper{position:absolute;top:0;left:0;background-color:transparent;display:block;width:100%}pre[data-line] .line-highlight{position:absolute;left:0;right:0;padding:inherit 0;margin-top:1em;background:hsla(24,20%,50%,.08);background:linear-gradient(to right,hsla(24,20%,50%,.1) 70%,hsla(24,20%,50%,0));pointer-events:none;line-height:inherit;white-space:pre}pre[data-line] .line-highlight:before,pre[data-line] .line-highlight[data-end]:after{content:attr(data-start);position:absolute;top:.4em;left:.6em;min-width:1em;padding:0 .5em;background-color:hsla(24,20%,50%,.4);color:#f4f1ef;font:bold 65%/1.5 sans-serif;text-align:center;vertical-align:.3em;border-radius:999px;text-shadow:none;box-shadow:0 1px #fff}pre[data-line] .line-highlight[data-end]:after{content:attr(data-end);top:auto;bottom:.4em}html body{font-family:'Helvetica Neue',Helvetica,'Segoe UI',Arial,freesans,sans-serif;font-size:16px;line-height:1.6;color:#c5c8c6;background-color:#1d1f21;overflow:initial;box-sizing:border-box;word-wrap:break-word}html body>:first-child{margin-top:0}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{line-height:1.2;margin-top:1em;margin-bottom:16px;color:#fff}html body h1{font-size:2.25em;font-weight:300;padding-bottom:.3em}html body h2{font-size:1.75em;font-weight:400;padding-bottom:.3em}html body h3{font-size:1.5em;font-weight:500}html body h4{font-size:1.25em;font-weight:600}html body h5{font-size:1.1em;font-weight:600}html body h6{font-size:1em;font-weight:600}html body h1,html body h2,html body h3,html body h4,html body h5{font-weight:600}html body h5{font-size:1em}html body h6{color:#9ba09d}html body strong{color:#fff}html body del{color:#9ba09d}html body a:not([href]){color:inherit;text-decoration:none}html body a{color:#ddd;text-decoration:none}html body a:hover{color:#cecece;text-decoration:none}html body img{max-width:100%}html body>p{margin-top:0;margin-bottom:16px;word-wrap:break-word}html body>ol,html body>ul{margin-bottom:16px}html body ol,html body ul{padding-left:2em}html body ol.no-list,html body ul.no-list{padding:0;list-style-type:none}html body ol ol,html body ol ul,html body ul ol,html body ul ul{margin-top:0;margin-bottom:0}html body li{margin-bottom:0}html body li.task-list-item{list-style:none}html body li>p{margin-top:0;margin-bottom:0}html body .task-list-item-checkbox{margin:0 .2em .25em -1.8em;vertical-align:middle}html body .task-list-item-checkbox:hover{cursor:pointer}html body blockquote{margin:16px 0;font-size:inherit;padding:0 15px;color:#9ba09d;background-color:#303337;border-left:4px solid #43484c}html body blockquote>:first-child{margin-top:0}html body blockquote>:last-child{margin-bottom:0}html body hr{height:4px;margin:32px 0;background-color:#43484c;border:0 none}html body table{margin:10px 0 15px 0;border-collapse:collapse;border-spacing:0;display:block;width:100%;overflow:auto;word-break:normal;word-break:keep-all}html body table th{font-weight:700;color:#fff}html body table td,html body table th{border:1px solid #43484c;padding:6px 13px}html body dl{padding:0}html body dl dt{padding:0;margin-top:16px;font-size:1em;font-style:italic;font-weight:700}html body dl dd{padding:0 16px;margin-bottom:16px}html body code{font-family:Menlo,Monaco,Consolas,'Courier New',monospace;font-size:.85em;color:#fff;background-color:#303337;border-radius:3px;padding:.2em 0}html body code::after,html body code::before{letter-spacing:-.2em;content:'\00a0'}html body pre>code{padding:0;margin:0;word-break:normal;white-space:pre;background:0 0;border:0}html body .highlight{margin-bottom:16px}html body .highlight pre,html body pre{padding:1em;overflow:auto;line-height:1.45;border:#43484c;border-radius:3px}html body .highlight pre{margin-bottom:0;word-break:normal}html body pre code,html body pre tt{display:inline;max-width:initial;padding:0;margin:0;overflow:initial;line-height:inherit;word-wrap:normal;background-color:transparent;border:0}html body pre code:after,html body pre code:before,html body pre tt:after,html body pre tt:before{content:normal}html body blockquote,html body dl,html body ol,html body p,html body pre,html body ul{margin-top:0;margin-bottom:16px}html body kbd{color:#fff;border:1px solid #43484c;border-bottom:2px solid #35393c;padding:2px 4px;background-color:#303337;border-radius:3px}@media print{html body{background-color:#1d1f21}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{color:#fff;page-break-after:avoid}html body blockquote{color:#9ba09d}html body pre{page-break-inside:avoid}html body table{display:table}html body img{display:block;max-width:100%;max-height:100%}html body code,html body pre{word-wrap:break-word;white-space:pre}}html body a{text-decoration:underline}.markdown-preview{width:100%;height:100%;box-sizing:border-box}.markdown-preview ul{list-style:disc}.markdown-preview ul ul{list-style:circle}.markdown-preview ul ul ul{list-style:square}.markdown-preview ol{list-style:decimal}.markdown-preview ol ol,.markdown-preview ul ol{list-style-type:lower-roman}.markdown-preview ol ol ol,.markdown-preview ol ul ol,.markdown-preview ul ol ol,.markdown-preview ul ul ol{list-style-type:lower-alpha}.markdown-preview .newpage,.markdown-preview .pagebreak{page-break-before:always}.markdown-preview pre.line-numbers{position:relative;padding-left:3.8em;counter-reset:linenumber}.markdown-preview pre.line-numbers>code{position:relative}.markdown-preview pre.line-numbers .line-numbers-rows{position:absolute;pointer-events:none;top:1em;font-size:100%;left:0;width:3em;letter-spacing:-1px;border-right:1px solid #999;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.markdown-preview pre.line-numbers .line-numbers-rows>span{pointer-events:none;display:block;counter-increment:linenumber}.markdown-preview pre.line-numbers .line-numbers-rows>span:before{content:counter(linenumber);color:#999;display:block;padding-right:.8em;text-align:right}.markdown-preview .mathjax-exps .MathJax_Display{text-align:center!important}.markdown-preview:not([data-for=preview]) .code-chunk .code-chunk-btn-group{display:none}.markdown-preview:not([data-for=preview]) .code-chunk .status{display:none}.markdown-preview:not([data-for=preview]) .code-chunk .output-div{margin-bottom:16px}.markdown-preview .md-toc{padding:0}.markdown-preview .md-toc .md-toc-link-wrapper .md-toc-link{display:inline;padding:.25rem 0}.markdown-preview .md-toc .md-toc-link-wrapper .md-toc-link div,.markdown-preview .md-toc .md-toc-link-wrapper .md-toc-link p{display:inline}.markdown-preview .md-toc .md-toc-link-wrapper.highlighted .md-toc-link{font-weight:800}.scrollbar-style::-webkit-scrollbar{width:8px}.scrollbar-style::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}.scrollbar-style::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,.66);border:4px solid rgba(150,150,150,.66);background-clip:content-box}html body[for=html-export]:not([data-presentation-mode]){position:relative;width:100%;height:100%;top:0;left:0;margin:0;padding:0;overflow:auto}html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{position:relative;top:0;min-height:100vh}@media screen and (min-width:914px){html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{padding:2em calc(50% - 457px + 2em)}}@media screen and (max-width:914px){html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{font-size:14px!important;padding:1em}}@media print{html body[for=html-export]:not([data-presentation-mode]) #sidebar-toc-btn{display:none}}html body[for=html-export]:not([data-presentation-mode]) #sidebar-toc-btn{position:fixed;bottom:8px;left:8px;font-size:28px;cursor:pointer;color:inherit;z-index:99;width:32px;text-align:center;opacity:.4}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] #sidebar-toc-btn{opacity:1}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc{position:fixed;top:0;left:0;width:300px;height:100%;padding:32px 0 48px 0;font-size:14px;box-shadow:0 0 4px rgba(150,150,150,.33);box-sizing:border-box;overflow:auto;background-color:inherit}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar{width:8px}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,.66);border:4px solid rgba(150,150,150,.66);background-clip:content-box}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc a{text-decoration:none}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc{padding:0 16px}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper .md-toc-link{display:inline;padding:.25rem 0}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper .md-toc-link div,html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper .md-toc-link p{display:inline}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper.highlighted .md-toc-link{font-weight:800}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{left:300px;width:calc(100% - 300px);padding:2em calc(50% - 457px - 300px / 2);margin:0;box-sizing:border-box}@media screen and (max-width:1274px){html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{width:100%}}html body[for=html-export]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .markdown-preview{left:50%;transform:translateX(-50%)}html body[for=html-export]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .md-sidebar-toc{display:none}
/* Please visit the URL below for more information: */
/*   https://shd101wyy.github.io/markdown-preview-enhanced/#/customize-css */

      </style>
      <!-- The content below will be included at the end of the <head> element. --><script type="text/javascript">
  document.addEventListener("DOMContentLoaded", function () {
    // your code here
  });
</script></head><body for="html-export">
    
    
      <div class="crossnote markdown-preview  ">
      
<h1 id="arc-prize-teams-hrm-analysis">ARC Prize Team's HRM Analysis </h1>
<ul>
<li><a href="https://arcprize.org/blog/hrm-analysis">The Hidden Drivers of HRM's Performance on ARC-AGI</a></li>
<li>2025-06; Chollet, Knoop, Schürholt</li>
</ul>

<div class="md-toc">
<details style="padding:0;;padding-left:0px;" open="">
        <summary class="md-toc-link-wrapper">
          <a href="#arc-prize-teams-hrm-analysis" class="md-toc-link"><p>ARC Prize Team's HRM Analysis</p>
</a>
          </summary>
        <div>
          <div class="md-toc-link-wrapper" style="padding:0;;display:list-item;list-style:square;margin-left:42px">
          <a href="#high-level-summary" class="md-toc-link">
            <p>High-Level Summary</p>

          </a></div><div class="md-toc-link-wrapper" style="padding:0;;display:list-item;list-style:square;margin-left:42px">
          <a href="#summary" class="md-toc-link">
            <p>Summary</p>

          </a></div><details style="padding:0;;padding-left:24px;" open="">
        <summary class="md-toc-link-wrapper">
          <a href="#analysis" class="md-toc-link"><p>Analysis</p>
</a>
          </summary>
        <div>
          <div class="md-toc-link-wrapper" style="padding:0;;display:list-item;list-style:square;margin-left:42px">
          <a href="#finding-1-minimal-impact-from-hierarchical-architecture" class="md-toc-link">
            <p>Finding #1: Minimal Impact from "Hierarchical" Architecture</p>

          </a></div><div class="md-toc-link-wrapper" style="padding:0;;display:list-item;list-style:square;margin-left:42px">
          <a href="#finding-2-outer-loop-refinement-drives-gains" class="md-toc-link">
            <p>Finding #2: "Outer Loop" Refinement Drives Gains</p>

          </a></div><div class="md-toc-link-wrapper" style="padding:0;;display:list-item;list-style:square;margin-left:42px">
          <a href="#finding-3-limited-impact-of-transfer-learning" class="md-toc-link">
            <p>Finding #3: Limited Impact of Transfer Learning</p>

          </a></div><div class="md-toc-link-wrapper" style="padding:0;;display:list-item;list-style:square;margin-left:42px">
          <a href="#finding-4-pretraining-task-augmentation-is-critical" class="md-toc-link">
            <p>Finding #4: Pretraining Task Augmentation Is Critical</p>

          </a></div>
        </div>
      </details>
    <div class="md-toc-link-wrapper" style="padding:0;;display:list-item;list-style:square;margin-left:42px">
          <a href="#other-technical-observations" class="md-toc-link">
            <p>Other Technical Observations</p>

          </a></div>
        </div>
      </details>
    
</div>
<h2 id="high-level-summary">High-Level Summary </h2>
<ul>
<li>The <em>Hierarchical Reasoning Model</em> (HRM) is a small (~27M), 'hierarchical' model</li>
<li>A recurrent architecture modelled on hierarchical and multi-timescale processing in human brains</li>
<li>Attains significant computational depth whilst maintaining both training stability and efficiency</li>
</ul>
<p>This overview assumes familiarity with the architecture used in HRM. This can be found in the HRM <a href="HRM.html">summary</a>, particularly the <a href="HRM.html#framework"><em>Framework</em></a> section.</p>
<h2 id="summary">Summary </h2>
<p>The official ARC team have analysed HRM:</p>
<blockquote>
<p><a href="https://arcprize.org/blog/hrm-analysis">https://arcprize.org/blog/hrm-analysis</a>.</p>
</blockquote>
<p>First, the results were <em>approximately</em> reproduces on the semi-private sets.</p>
<ol>
<li>ARC-AGI-1 @ 32%: impressive for such a small model, but not state of the art.</li>
<li>ARC-AGI-2 @ 2%: non-zero score shows some signal, but not material progress.</li>
</ol>
<p>A series of ablation studies call into question the narrative around HRM.</p>
<ol>
<li>The "hierarchical" architecture had minimal performance impact vs similarly sized transformer.</li>
<li>The "outer loop" refinement drove the performance, particularly at training time.</li>
<li>Cross-task transfer learning had limited benefits; most of the performance comes from memorising solutions.</li>
<li>Pre-training task augmentation is <em>critical</em>; little impact at inference time.</li>
</ol>
<p>Findings 2 &amp; 3 suggest the approach is fundamentally similar to <a href="https://arxiv.org/pdf/2411.02272"><em>ARC-AGI without Pretraining</em></a> (Liao &amp; Gu, '24).</p>
<h2 id="analysis">Analysis </h2>
<p>The four main components of the HRM paper are investigated:
the model architecture,
the high–low hierarchical computation,
the outer refinement loop
and
the use of data augmentation.</p>
<p>Specifically, the following were tested, taken verbatim from the <a href="https://arcprize.org/blog/hrm-analysis#analyzing-hrms-contribution-to-arc-scores">relevant section</a>.</p>
<ul>
<li>"Hierarchical" H and L loop performance contributions
<ul>
<li>What performance does HRM provide over a base transformer?</li>
<li>What impact does varying the hierarchical compute have?</li>
</ul>
</li>
<li>Varying the max "halt or continue" loops
<ul>
<li>How well does the ACT grader do compared to a fixed number of loops (with no decision to halt refinements)?</li>
</ul>
</li>
<li>Impact of cross-task transfer learning
<ul>
<li>What is the impact of the inclusion of the training set tasks and the ConceptARC tasks at training time, compared to only training on the evaluation tasks?</li>
</ul>
</li>
<li>Augmentation count
<ul>
<li>Varying the number of augmentations that were created from each task.</li>
</ul>
</li>
<li>Model/training variations (size and duration)</li>
</ul>
<h3 id="finding-1-minimal-impact-from-hierarchical-architecture">Finding #1: Minimal Impact from "Hierarchical" Architecture </h3>
<p>Two experiments were performed.</p>
<ol>
<li>Vary the amount of iterations in the hierarchical components.</li>
<li>Replace the HRM with a similarly sized transformer.</li>
</ol>
<p><img src="attachments/HRM%20-%20ARC%20-%20HRM%20vs%20Transformer.png" alt="HRM vs Transformer by Refinement Loops" style="display: block; margin: 0 auto"></p>
<p>On ARC-AGI-1, a regular transformer comes within ~5pp of the HRM model, without hyperparameter optimisation. Varying the number of H- and L-level steps vs the baseline (L=2 and H=2) only decreased the performance.</p>
<p>These suggest that, whilst the HRM architecture provides a small benefit, it is not the main driver of HRM's performance on ARC-AGI.</p>
<h3 id="finding-2-outer-loop-refinement-drives-gains">Finding #2: "Outer Loop" Refinement Drives Gains </h3>
<p>The model feeds its high-level output back into itself, allowing iterative refinements. It uses "adaptive computational time" (ACT) to control the number of iterations. To analyse this, the maximum number of outer loops during <em>training</em> (forcing maximum number during inference, as in the HRM implementation) was varied. Below, the mark "ACT N Loops" means a <em>maximum</em> of N loops, with ACT early stopping.</p>
<p><img src="attachments/HRM%20-%20ARC%20-%20Performance%20by%20Max%20Loops.png" alt="Performance by Max Loops" style="display: block; margin: 0 auto"></p>
<p>Clearly, this parameter has a large impact, doubling ~20% to ~40%. Interestingly, using ACT with <em>maximum</em> of 16 vs fixed 16 is a slight improvement.</p>
<p>To understand refinement during training vs inference, the number of loops was varied during inference too.</p>
<p><img src="attachments/HRM%20-%20ARC%20-%20Performance%20by%20ACT%20Type.png" alt="Performance by ACT Type" style="display: block; margin: 0 auto"></p>
<p>Training with more refinement makes a big difference (doubles, &gt;15pp) when no inference refinement is allowed. More than 4 refinement loops <em>for inference</em> has little impact.</p>
<h3 id="finding-3-limited-impact-of-transfer-learning">Finding #3: Limited Impact of Transfer Learning </h3>
<p>The original HRM is trained on augmented version of the <em>demonstration</em> (<em>example</em>) <em>pairs</em>, from both the <em>training</em> and <em>evaluation</em> sets; <a href="https://arxiv.org/abs/2305.07141">ConceptARC</a> is also used.</p>
<blockquote>
<p>NB. This does not imply data leakage: the model never sees, at training time, the <em>test</em> (<em>problem</em>) pairs. Fundamentally, this is a <em>zero-pretraining test-time training</em> approach. To emphasise, it uses the example pairs, as well as augmented versions, from the entire evaluation set to train.</p>
<p>This certainly raises questions about its generalisability: it relies heavily on data augmentation, including for other tasks such as Sudoku.</p>
</blockquote>
<p>This is similar to <a href="https://arxiv.org/pdf/2411.02272"><em>ARC-AGI without Pretraining</em></a> (Liao &amp; Gu, '24), and amounts to using the model as a kind of program synthesis substrate: gradient descent on example pairs encodes in the weights a program that performs the task.</p>
<p>To understand <em>cross-task</em> transfer learning, the 400 <em>training</em> tasks and 160 ConceptARC tasks were removed. This dropped performance from 41% to 31%. The ARC Prize team suggests the performance is driven by test-time training. I'm not so sure.</p>
<ul>
<li>As they note, there is <em>some</em> cross-task learning between the 400 tasks in the eval set—which comprise &gt;40% of all the data.</li>
<li>Perhaps cross-task learning is important, but 400 samples is enough to get good performance (31%). The remainder bump this up non-trivially (to 41%).</li>
</ul>
<p>The ARC Prize team suggest a stronger version: train on <em>just one</em> evaluation task (with augmentations). This is <a href="https://arxiv.org/pdf/2411.02272">Liao &amp; Gu's set-up</a>. They <em>speculate</em> the results would be similar (21% pass@2).</p>
<p>Another interesting test would be to train <em>solely</em> on the training set, and evaluate on the eval set. Augmentations can still be used: create n augmented versions → make predictions → undo augmentation → majority selection. The weights wouldn't be updated during these augmentations, though.</p>
<h3 id="finding-4-pretraining-task-augmentation-is-critical">Finding #4: Pretraining Task Augmentation Is Critical </h3>
<p>HRM makes predictions for all augmented versions of a task, then reverts the augmentation to place in the original format. Majority voting selects the final candidate(s). Two modifications are tested.</p>
<ol>
<li>Changing the maximum number of augmentations when compiling the dataset.</li>
<li>Changing the maximum number of predictions used for majority voting.</li>
</ol>
<p>The latter is restricted to <em>reducing</em> the number, since HRM can't process augmentation types not encountered during training.</p>
<p><img src="attachments/HRM%20-%20ARC%20-%20Performance%20by%20Num%20Augmentations.png" alt="Performance by Number of Augmentations" style="display: block; margin: 0 auto"></p>
<p>Two trends are exhibited.</p>
<ol>
<li>Augmentations help significantly. But, 300 is plenty, vs the 1000 used by HRM; in fact, 30 gets within 4pp of the max.</li>
<li>Augmentation during training appears to be more important than for a bigger voting pool: "the lines at the top flatten out quickly" (and the horizontal axis is on a log scale).</li>
</ol>
<h2 id="other-technical-observations">Other Technical Observations </h2>
<p>First and foremost, the dataset: HRM "flattens" all input–output pairs. Each pair gets an id, which consists of the task hash and a code for the augmentation applied.</p>
<p>At training and inference time, the model <em>only</em> receives the input and id—there is no few-shot context with other examples of the task. The model has to learn to relate an id to a specific transformation.</p>
<p>To that end, the model feeds the id into a large embedding layer; without this, it wouldn't know what to do with an input. This presents a major limitation: the model can <em>only</em> be applied on puzzles with ids it's seen in training.</p>
<p>In conversation with the ARC Prize team, the HRM authors claimed that changing the embeddings for few-shot contexts is complex engineeringwise. As such, inference data <em>has</em> to be part of the training dataset.</p>
<p>Last, whilst the refinement loop clearly has significant impact on performance, HRM is purely <em>transductive</em>: at no point is the underlying program explicit. The ARC Prize team hypothesise this won't generalise.</p>

      </div>
      
      
    
    
    
    
    
    
  
    </body></html>